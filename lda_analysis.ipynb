{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "491c49d5-213b-4348-8474-e47617c387d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.26.4)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.1\n",
      "    Uninstalling scipy-1.15.1:\n",
      "      Successfully uninstalled scipy-1.15.1\n",
      "Successfully installed gensim-4.3.3 scipy-1.13.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ec8464-e2bd-4077-96c5-bd17656dc6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import re\n",
    "from google.cloud import storage\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de59d299-c2f3-4884-9d0c-1562b1d60864",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4ad892b-0c8a-4348-843e-881ebf0f1bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset from GCS\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"my-bert-topic-model\"\n",
    "FILE_NAME = \"call_transcripts.xlsx\"\n",
    "client = storage.Client()\n",
    "bucket = client.bucket(BUCKET_NAME)\n",
    "blob = bucket.blob(FILE_NAME)\n",
    "data = blob.download_as_bytes()\n",
    "df = pd.read_excel(io.BytesIO(data))\n",
    "print(\"Loaded dataset from GCS\")\n",
    "df = df.dropna(subset=[\"transcript\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa6da159-0ac9-4b66-ab1c-bc9d7aca2f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1b3eaba-6cba-487c-baf8-e87aee07ca1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"cleaned_transcript\"] = df[\"transcript\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c03077-4479-4584-8954-d41588c69938",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [operator, good, afternoon, name, david, ill, ...\n",
      "1    [operator, good, afternoon, name, david, ill, ...\n",
      "2    [operator, good, afternoon, name, jl, conferen...\n",
      "3    [operator, good, afternoon, name, rob, ill, co...\n",
      "4    [operator, good, afternoon, name, david, ill, ...\n",
      "Name: cleaned_transcript, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"cleaned_transcript\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c944ca-3692-4be9-8b18-cff3e140f07e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df[\"cleaned_transcript\"].tolist())\n",
    "corpus = [dictionary.doc2bow(text) for text in df[\"cleaned_transcript\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ee08a19-9fec-4e87-97a9-3d8c1e1b4105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_TOPICS = 10\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=NUM_TOPICS, passes=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72ac3f83-c14e-417b-97fc-0be0fc909350",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.016*\"quarter\" + 0.009*\"revenue\" + 0.008*\"think\" + 0.008*\"year\" + 0.007*\"question\"')\n",
      "(1, '0.015*\"quarter\" + 0.012*\"growth\" + 0.010*\"year\" + 0.008*\"new\" + 0.008*\"business\"')\n",
      "(2, '0.013*\"fiscal\" + 0.012*\"quarter\" + 0.010*\"dram\" + 0.010*\"nand\" + 0.010*\"growth\"')\n",
      "(3, '0.010*\"quarter\" + 0.008*\"year\" + 0.008*\"think\" + 0.007*\"billion\" + 0.006*\"growth\"')\n",
      "(4, '0.014*\"revenue\" + 0.012*\"growth\" + 0.009*\"quarter\" + 0.008*\"cloud\" + 0.008*\"business\"')\n",
      "(5, '0.012*\"year\" + 0.011*\"growth\" + 0.011*\"customers\" + 0.011*\"revenue\" + 0.009*\"business\"')\n",
      "(6, '0.016*\"ai\" + 0.009*\"data\" + 0.006*\"quarter\" + 0.006*\"nvidia\" + 0.006*\"year\"')\n",
      "(7, '0.013*\"billion\" + 0.011*\"year\" + 0.010*\"revenue\" + 0.009*\"quarter\" + 0.008*\"iphone\"')\n",
      "(8, '0.010*\"quarter\" + 0.009*\"customers\" + 0.008*\"year\" + 0.008*\"million\" + 0.007*\"cloud\"')\n",
      "(9, '0.017*\"cloud\" + 0.011*\"revenue\" + 0.009*\"q\" + 0.008*\"growth\" + 0.008*\"quarter\"')\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec50d23-aec0-4b85-ad4b-4466575e5b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
